{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/zmuhls/ccny-data-science/blob/main/assets/notebooks/sample_pythonScript.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f024b3c3",
      "metadata": {
        "id": "f024b3c3"
      },
      "source": [
        "# Text Analysis Workflow\n",
        "\n",
        "This notebook outlines a simple text analysis process that iterates over its results with further analysis.  \n",
        "\n",
        "1. **Import Libraries**: Load necessary tools for text processing and visualization\n",
        "2. **Define Functions**: Create helper functions to handle text\n",
        "3. **Set Variables**: Set file paths and key variables\n",
        "4. **Read File**: Load the text for analysis\n",
        "5. **Process Text**: Clean and count word frequencies\n",
        "6. **Show Term Results**: Display the most frequent words\n",
        "7. **Use NLTK**: Use the bigram function from the Natural Language Toolkit (NLTK)\n",
        "8. **Show Bigram Results**: Display the most frequent co-occuring words\n",
        "\n",
        "______"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e590eb9a-2898-4df1-9079-6e45ffd1b1a4",
      "metadata": {
        "id": "e590eb9a-2898-4df1-9079-6e45ffd1b1a4"
      },
      "outputs": [],
      "source": [
        "# Import the necessary libraries to begin the script\n",
        "import re  # Regular expressions for text processing\n",
        "from collections import Counter  # Count occurrences of elements like words\n",
        "\n",
        "# Define the function to split up a text into individual words\n",
        "def split_into_words(any_chunk_of_text):\n",
        "    lowercase_text = any_chunk_of_text.lower()  # Convert the text to lowercase to ensure uniformity\n",
        "    split_words = re.split(r\"\\W+\", lowercase_text)  # Use regular expressions to split the text by any non-word character\n",
        "    return split_words  # Return the list of words"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6cef8430-f830-44cf-8cdc-5abf3005f000",
      "metadata": {
        "id": "6cef8430-f830-44cf-8cdc-5abf3005f000"
      },
      "outputs": [],
      "source": [
        "# Define the filepath and assign variables\n",
        "tos_file = \"/content/nest_tos.txt\"\n",
        "\n",
        "number_of_desired_words = 20\n",
        "\n",
        "# Create a list of stopwords\n",
        "stopwords = ['i', 'me', 'my', 'myself', 'we', 'our', 'ours', 'ourselves', 'you', 'your', 'yours',\n",
        " 'yourself', 'yourselves', 'he', 'him', 'his', 'himself', 'she', 'her', 'hers',\n",
        " 'herself', 'it', 'its', 'itself', 'they', 'them', 'their', 'theirs', 'themselves',\n",
        " 'what', 'which', 'who', 'whom', 'this', 'that', 'these', 'those', 'am', 'is', 'are',\n",
        " 'was', 'were', 'be', 'been', 'being', 'have', 'has', 'had', 'having', 'do', 'does',\n",
        " 'did', 'doing', 'a', 'an', 'the', 'and', 'but', 'if', 'or', 'because', 'as', 'until',\n",
        " 'while', 'of', 'at', 'by', 'for', 'with', 'about', 'against', 'between', 'into',\n",
        " 'through', 'during', 'before', 'after', 'above', 'below', 'to', 'from', 'up', 'down',\n",
        " 'in', 'out', 'on', 'off', 'over', 'under', 'again', 'further', 'then', 'once', 'here',\n",
        " 'there', 'when', 'where', 'why', 'how', 'all', 'any', 'both', 'each', 'few', 'more', 'mr',\n",
        " 'most', 'other', 'some', 'such', 'no', 'nor', 'not', 'only', 'own', 'same', 'so', 'tm', 'said',\n",
        " 'than', 'too', 'very', 's', 't', 'can', 'will', 'just', 'don', 'should', 'now', 've', 'll', 'amp', 'gutenberg', 'project']\n",
        "\n",
        "# Read in the file\n",
        "tos_text = open(tos_file, encoding=\"utf-8\").read()\n",
        "pvp_text = open(pvp_file, encoding=\"utf-8\").read()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f4396ef4-cf1c-4d36-b9b8-bdb5d2f8ec02",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "f4396ef4-cf1c-4d36-b9b8-bdb5d2f8ec02",
        "outputId": "94727fa7-3d23-42f2-ac01-5f5c0a5f9b6c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[('nest', 253),\n",
              " ('services', 226),\n",
              " ('products', 153),\n",
              " ('may', 102),\n",
              " ('terms', 94),\n",
              " ('use', 90),\n",
              " ('third', 76),\n",
              " ('party', 72),\n",
              " ('agree', 59),\n",
              " ('service', 54),\n",
              " ('arbitration', 41),\n",
              " ('product', 41),\n",
              " ('information', 41),\n",
              " ('content', 39),\n",
              " ('including', 38),\n",
              " ('access', 37),\n",
              " ('monitoring', 35),\n",
              " ('applicable', 33),\n",
              " ('account', 31),\n",
              " ('law', 30)]"
            ]
          },
          "metadata": {},
          "execution_count": 38
        }
      ],
      "source": [
        "# Tokenize and count frequency of meaningful terms in google nest's terms of service or privacy policy\n",
        "all_of_words = split_into_words(tos_text)\n",
        "meaningful_words = [word for word in all_of_words if word not in stopwords]\n",
        "meaningful_words_tally = Counter(meaningful_words)\n",
        "most_frequent_meaningful_words = meaningful_words_tally.most_common(number_of_desired_words)\n",
        "\n",
        "# Output results\n",
        "most_frequent_meaningful_words"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from nltk import bigrams  # Import NLTK's bigrams function\n",
        "\n",
        "# Generate bigrams (collocations) from meaningful words\n",
        "word_bigrams = list(bigrams(meaningful_words))\n",
        "\n",
        "# Count the frequency of bigrams\n",
        "bigrams_tally = Counter(word_bigrams)\n",
        "most_frequent_bigrams = bigrams_tally.most_common(20)\n",
        "\n",
        "# Output results\n",
        "most_frequent_bigrams"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oE5yhB1Ojyy7",
        "outputId": "b65d099e-f601-4d18-c397-58850e0d754e"
      },
      "id": "oE5yhB1Ojyy7",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[(('products', 'services'), 72),\n",
              " (('third', 'party'), 64),\n",
              " (('services', 'products'), 44),\n",
              " (('use', 'services'), 23),\n",
              " (('pro', 'monitoring'), 21),\n",
              " (('party', 'products'), 19),\n",
              " (('nest', 'com'), 18),\n",
              " (('nest', 'products'), 17),\n",
              " (('applicable', 'law'), 15),\n",
              " (('nest', 'may'), 14),\n",
              " (('services', 'including'), 13),\n",
              " (('https', 'nest'), 12),\n",
              " (('third', 'parties'), 12),\n",
              " (('use', 'products'), 12),\n",
              " (('mobile', 'apps'), 11),\n",
              " (('authorised', 'users'), 11),\n",
              " (('using', 'services'), 11),\n",
              " (('understand', 'agree'), 11),\n",
              " (('access', 'use'), 10),\n",
              " (('services', 'may'), 10)]"
            ]
          },
          "metadata": {},
          "execution_count": 39
        }
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.12.1"
    },
    "colab": {
      "provenance": [],
      "include_colab_link": true
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}